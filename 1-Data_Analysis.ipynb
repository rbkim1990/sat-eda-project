{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: SAT & ACT Analysis\n",
    "### Data Cleaning and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose of this Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Standardized college tests are the key for high school seniors need to have in order to access the world of college. Evaluating students across different locations, demographics, and societies through a standardized test is one of the ways that colleges can get an objective idea of how prepared a student is to succeed in college._ \n",
    "\n",
    "_There are two main standardized college entrance exams: the **SAT** (Scholastic Aptitude Test) and the **ACT** (American College Testing). We will be comparing various facets of both tests to discover any interesting patterns, as well as focus in on **expanding the SAT participation rate in Alaska.**_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executive Summary\n",
    "### Contents:\n",
    "- [Data Importing and Cleaning](#Importing-and-Cleaning-Data)\n",
    "- [Exploratory Data Analysis](#Exploratory-Data-Analysis)\n",
    "- [Data Visualization](#Visualize-the-data)\n",
    "- [Descriptive and Inferential Statistics](#Descriptive-and-Inferential-Statistics)\n",
    "- [Outside Research](#Outside-Research)\n",
    "- [Conclusions and Recommendations](#Conclusions-and-Recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T21:38:53.473849Z",
     "start_time": "2019-06-12T21:38:52.414889Z"
    }
   },
   "outputs": [],
   "source": [
    "# Library and function imports:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Separate Python file with simple functions to clean and engineer the data\n",
    "from simple_functions import standardizer, pct_changer, remove_pct, remove_commas\n",
    "from simple_functions import remove_periods, divide_million, stan_dev, draw_heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T21:38:53.491717Z",
     "start_time": "2019-06-12T21:38:53.476455Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loaded the 2017 ACT and SAT data in Pandas DataFrames\n",
    "# This data was manually crafted from information on the SAT and ACT website.\n",
    "sat17 = pd.read_csv('./data/sat_2017.csv');\n",
    "act17 = pd.read_csv('./data/act_2017.csv');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T21:38:53.507503Z",
     "start_time": "2019-06-12T21:38:53.493643Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>Evidence-Based Reading and Writing</th>\n",
       "      <th>Math</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>5%</td>\n",
       "      <td>593</td>\n",
       "      <td>572</td>\n",
       "      <td>1165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>38%</td>\n",
       "      <td>547</td>\n",
       "      <td>533</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>30%</td>\n",
       "      <td>563</td>\n",
       "      <td>553</td>\n",
       "      <td>1116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>3%</td>\n",
       "      <td>614</td>\n",
       "      <td>594</td>\n",
       "      <td>1208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>53%</td>\n",
       "      <td>531</td>\n",
       "      <td>524</td>\n",
       "      <td>1055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        State Participation  Evidence-Based Reading and Writing  Math  Total\n",
       "0     Alabama            5%                                 593   572   1165\n",
       "1      Alaska           38%                                 547   533   1080\n",
       "2     Arizona           30%                                 563   553   1116\n",
       "3    Arkansas            3%                                 614   594   1208\n",
       "4  California           53%                                 531   524   1055"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking a preliminary look at the data\n",
    "sat17.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T21:38:53.527109Z",
     "start_time": "2019-06-12T21:38:53.510534Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>English</th>\n",
       "      <th>Math</th>\n",
       "      <th>Reading</th>\n",
       "      <th>Science</th>\n",
       "      <th>Composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>100%</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.4</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>65%</td>\n",
       "      <td>18.7</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.4</td>\n",
       "      <td>19.9</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>62%</td>\n",
       "      <td>18.6</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.1</td>\n",
       "      <td>19.8</td>\n",
       "      <td>19.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>100%</td>\n",
       "      <td>18.9</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>31%</td>\n",
       "      <td>22.5</td>\n",
       "      <td>22.7</td>\n",
       "      <td>23.1</td>\n",
       "      <td>22.2</td>\n",
       "      <td>22.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        State Participation  English  Math  Reading  Science Composite\n",
       "0     Alabama          100%     18.9  18.4     19.7     19.4      19.2\n",
       "1      Alaska           65%     18.7  19.8     20.4     19.9      19.8\n",
       "2     Arizona           62%     18.6  19.8     20.1     19.8      19.7\n",
       "3    Arkansas          100%     18.9  19.0     19.7     19.5      19.4\n",
       "4  California           31%     22.5  22.7     23.1     22.2      22.8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act17.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Impressions of the Data\n",
    "*Both sets of data report the subscore and total score averages for every state for their respective test. Included in both data sets is participation rate per state. ACT has a score range from 1 to 36 and the SAT has a score range from 400 to 1600. All data is within appropriate bounds (but closer inspection on the dataset reveals typo errors with Maryland's 2017 SAT Math score and 2017 ACT Science score).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T21:38:53.541279Z",
     "start_time": "2019-06-12T21:38:53.529549Z"
    }
   },
   "outputs": [],
   "source": [
    "# Used .loc() to correct Maryland's SAT Math value\n",
    "sat17.loc[20,'Math'] = 524\n",
    "\n",
    "# Used .loc() to correct Maryland's ACT Science value\n",
    "act17.loc[20, 'Science'] = 23.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T21:38:53.554268Z",
     "start_time": "2019-06-12T21:38:53.544020Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State                                 object\n",
       "Participation                         object\n",
       "Evidence-Based Reading and Writing     int64\n",
       "Math                                   int64\n",
       "Total                                  int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking a closer look at the data types, to see if they correctly describe the data\n",
    "# Any discrepancies can mean errors in the data\n",
    "sat17.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T21:38:53.566581Z",
     "start_time": "2019-06-12T21:38:53.559690Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State             object\n",
       "Participation     object\n",
       "English          float64\n",
       "Math             float64\n",
       "Reading          float64\n",
       "Science          float64\n",
       "Composite         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act17.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*For analysis, ACT Composite scores should be a float, but closer inspection reveals that there is an error in Wyoming's Composite score. Furthermore, participation (both for the ACT and SAT) would be most useful as a float value for the purposes of analysis and should, therefore, be converted.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T21:38:53.575932Z",
     "start_time": "2019-06-12T21:38:53.570526Z"
    }
   },
   "outputs": [],
   "source": [
    "# Correcting the participation data\n",
    "# Function found in the separate Python file\n",
    "\n",
    "sat17['Participation'] = sat17['Participation'].map(remove_pct)\n",
    "act17['Participation'] = act17['Participation'].map(remove_pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T21:38:53.586996Z",
     "start_time": "2019-06-12T21:38:53.580908Z"
    }
   },
   "outputs": [],
   "source": [
    "# Correcting Wyoming's ACT Composite score\n",
    "act17.loc[50, 'Composite'] = 20.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T21:38:53.594239Z",
     "start_time": "2019-06-12T21:38:53.589246Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now that Wyoming's ACT Composite score is a float, \n",
    "# We can change the ACT Composite score type from object to float\n",
    "act17['Composite'] = act17['Composite'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T21:38:53.606889Z",
     "start_time": "2019-06-12T21:38:53.599165Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State             object\n",
       "Participation      int64\n",
       "English          float64\n",
       "Math             float64\n",
       "Reading          float64\n",
       "Science          float64\n",
       "Composite        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirming corrected dtypes\n",
    "act17.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T21:38:53.619885Z",
     "start_time": "2019-06-12T21:38:53.609407Z"
    }
   },
   "outputs": [],
   "source": [
    "# Changing column names since we'll be combining 2018 test data\n",
    "# Renaming using a dictionary\n",
    "act_rename = {\n",
    "    'State' : 'state',\n",
    "    'Composite' : '2017_act_total',\n",
    "    'English' : '2017_act_eng',\n",
    "    'Math' : '2017_act_math',\n",
    "    'Reading' : '2017_act_read',\n",
    "    'Science' : '2017_act_science',\n",
    "    'Participation' : '2017_act_part'\n",
    "}\n",
    "\n",
    "sat_rename = {\n",
    "    'State': 'state',\n",
    "    'Participation' : '2017_sat_part',\n",
    "    'Evidence-Based Reading and Writing' : '2017_sat_read',\n",
    "    'Math' : '2017_sat_math',\n",
    "    'Total' : '2017_sat_total'   \n",
    "}\n",
    "\n",
    "act17.rename(act_rename, axis=1, inplace=True)\n",
    "sat17.rename(sat_rename,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T21:38:53.632071Z",
     "start_time": "2019-06-12T21:38:53.622747Z"
    }
   },
   "outputs": [],
   "source": [
    "# At this point, we need to merge the 2017 SAT and ACT data into one dataframe\n",
    "# Used the pd.merge() function to merge DataFrames\n",
    "merge = pd.merge(sat17,act17,on='state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T21:38:53.643710Z",
     "start_time": "2019-06-12T21:38:53.635221Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 51 entries, 0 to 50\n",
      "Data columns (total 11 columns):\n",
      "state               51 non-null object\n",
      "2017_sat_part       51 non-null int64\n",
      "2017_sat_read       51 non-null int64\n",
      "2017_sat_math       51 non-null int64\n",
      "2017_sat_total      51 non-null int64\n",
      "2017_act_part       51 non-null int64\n",
      "2017_act_eng        51 non-null float64\n",
      "2017_act_math       51 non-null float64\n",
      "2017_act_read       51 non-null float64\n",
      "2017_act_science    51 non-null float64\n",
      "2017_act_total      51 non-null float64\n",
      "dtypes: float64(5), int64(5), object(1)\n",
      "memory usage: 4.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check to confirm changes were made correctly\n",
    "merge.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T21:38:53.656182Z",
     "start_time": "2019-06-12T21:38:53.646335Z"
    }
   },
   "outputs": [],
   "source": [
    "# Saving the 2017 SAT and ACT merged data to an external .csv file\n",
    "merge.to_csv('./data/combined_2017.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2018 Data Import and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T21:38:53.671355Z",
     "start_time": "2019-06-12T21:38:53.659521Z"
    }
   },
   "outputs": [],
   "source": [
    "# We also have available the 2018 SAT and ACT data files\n",
    "# Reading in the appropriate data sets into DataFrames\n",
    "act18 = pd.read_csv('./data/act_2018.csv')\n",
    "sat18 = pd.read_csv('./data/sat_2018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T21:38:53.682775Z",
     "start_time": "2019-06-12T21:38:53.673947Z"
    }
   },
   "outputs": [],
   "source": [
    "# Changing participation rates into correct format, renaming columns,\n",
    "# dropping 'National' entry in ACT, merging the 2018 data, \n",
    "# and saving the resulting .csv file\n",
    "sat18['Participation'] = sat18['Participation'].map(remove_pct)\n",
    "act18['Participation'] = act18['Participation'].map(remove_pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T21:38:53.701611Z",
     "start_time": "2019-06-12T21:38:53.686266Z"
    }
   },
   "outputs": [],
   "source": [
    "sat18.rename({'State' : 'state', \n",
    "              'Total' : '2018_sat_total', \n",
    "              'Participation':'2018_sat_part',\n",
    "              'Evidence-Based Reading and Writing' : '2018_sat_read',\n",
    "              'Math' : '2018_sat_math'}, axis=1, inplace=True)\n",
    "act18.rename({'State': 'state', \n",
    "              'Composite': '2018_act_total',\n",
    "              'Participation' : '2018_act_part',},axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T21:38:53.718706Z",
     "start_time": "2019-06-12T21:38:53.703731Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# There was an extraneous row called \"National\" in the 2018 ACT data\n",
    "# Dropped the row, as it was unncessary for analysis\n",
    "act18[act18['state']=='National']\n",
    "act18 = act18.drop(27)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_At this point, I had a difficult time getting the resulting merged file to have the correct number of entries (51). I looked into the original files and realized that 'Oklahoma' and 'Mississippi' were misspelled in the SAT 2018 file. I went ahead and manually changed those values, although doing so in Pandas would not have been difficult._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T21:38:53.728828Z",
     "start_time": "2019-06-12T21:38:53.721050Z"
    }
   },
   "outputs": [],
   "source": [
    "# Merging the 2018 SAT and ACT data into one dataframe\n",
    "merge18=pd.merge(sat18,act18,on='state')\n",
    "merge18.to_csv('./data/combined_2018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T21:38:53.733476Z",
     "start_time": "2019-06-12T21:38:53.730179Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 7)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirming if merge was successful\n",
    "merge18.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T21:38:53.745386Z",
     "start_time": "2019-06-12T21:38:53.736238Z"
    }
   },
   "outputs": [],
   "source": [
    "# Merging the 2017 and 2018 data\n",
    "final = pd.merge(merge,merge18,on='state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T21:38:53.759105Z",
     "start_time": "2019-06-12T21:38:53.752299Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 17)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking out the data to see if the process was successful\n",
    "final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_I wanted to standardize the ACT and SAT scores so that I can compare them directly later in the project. I decided to only standardize the composite (total) scores for both ACT and SAT. I created the function in the separate Python file._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T21:38:53.771026Z",
     "start_time": "2019-06-12T21:38:53.763503Z"
    }
   },
   "outputs": [],
   "source": [
    "final['2017_sat_total_standardized'] = standardizer(final['2017_sat_total'])\n",
    "final['2018_sat_total_standardized'] = standardizer(final['2018_sat_total'])\n",
    "final['2017_act_total_standardized'] = standardizer(final['2017_act_total'])\n",
    "final['2018_act_total_standardized'] = standardizer(final['2018_act_total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T21:38:53.810660Z",
     "start_time": "2019-06-12T21:38:53.773213Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>2017_sat_part</th>\n",
       "      <th>2017_sat_read</th>\n",
       "      <th>2017_sat_math</th>\n",
       "      <th>2017_sat_total</th>\n",
       "      <th>2017_act_part</th>\n",
       "      <th>2017_act_eng</th>\n",
       "      <th>2017_act_math</th>\n",
       "      <th>2017_act_read</th>\n",
       "      <th>2017_act_science</th>\n",
       "      <th>...</th>\n",
       "      <th>2018_sat_part</th>\n",
       "      <th>2018_sat_read</th>\n",
       "      <th>2018_sat_math</th>\n",
       "      <th>2018_sat_total</th>\n",
       "      <th>2018_act_part</th>\n",
       "      <th>2018_act_total</th>\n",
       "      <th>2017_sat_total_standardized</th>\n",
       "      <th>2018_sat_total_standardized</th>\n",
       "      <th>2017_act_total_standardized</th>\n",
       "      <th>2018_act_total_standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>5</td>\n",
       "      <td>593</td>\n",
       "      <td>572</td>\n",
       "      <td>1165</td>\n",
       "      <td>100</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.4</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.4</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>595</td>\n",
       "      <td>571</td>\n",
       "      <td>1166</td>\n",
       "      <td>100</td>\n",
       "      <td>19.1</td>\n",
       "      <td>0.424770</td>\n",
       "      <td>0.493207</td>\n",
       "      <td>-1.159348</td>\n",
       "      <td>-1.143654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>38</td>\n",
       "      <td>547</td>\n",
       "      <td>533</td>\n",
       "      <td>1080</td>\n",
       "      <td>65</td>\n",
       "      <td>18.7</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.4</td>\n",
       "      <td>19.9</td>\n",
       "      <td>...</td>\n",
       "      <td>43</td>\n",
       "      <td>562</td>\n",
       "      <td>544</td>\n",
       "      <td>1106</td>\n",
       "      <td>33</td>\n",
       "      <td>20.8</td>\n",
       "      <td>-0.503344</td>\n",
       "      <td>-0.150381</td>\n",
       "      <td>-0.859466</td>\n",
       "      <td>-0.332903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>30</td>\n",
       "      <td>563</td>\n",
       "      <td>553</td>\n",
       "      <td>1116</td>\n",
       "      <td>62</td>\n",
       "      <td>18.6</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.1</td>\n",
       "      <td>19.8</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>577</td>\n",
       "      <td>572</td>\n",
       "      <td>1149</td>\n",
       "      <td>66</td>\n",
       "      <td>19.2</td>\n",
       "      <td>-0.110260</td>\n",
       "      <td>0.310857</td>\n",
       "      <td>-0.909446</td>\n",
       "      <td>-1.095963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>3</td>\n",
       "      <td>614</td>\n",
       "      <td>594</td>\n",
       "      <td>1208</td>\n",
       "      <td>100</td>\n",
       "      <td>18.9</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>592</td>\n",
       "      <td>576</td>\n",
       "      <td>1169</td>\n",
       "      <td>100</td>\n",
       "      <td>19.4</td>\n",
       "      <td>0.894287</td>\n",
       "      <td>0.525386</td>\n",
       "      <td>-1.059388</td>\n",
       "      <td>-1.000580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>53</td>\n",
       "      <td>531</td>\n",
       "      <td>524</td>\n",
       "      <td>1055</td>\n",
       "      <td>31</td>\n",
       "      <td>22.5</td>\n",
       "      <td>22.7</td>\n",
       "      <td>23.1</td>\n",
       "      <td>22.2</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>540</td>\n",
       "      <td>536</td>\n",
       "      <td>1076</td>\n",
       "      <td>27</td>\n",
       "      <td>22.7</td>\n",
       "      <td>-0.776319</td>\n",
       "      <td>-0.472174</td>\n",
       "      <td>0.639945</td>\n",
       "      <td>0.573230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        state  2017_sat_part  2017_sat_read  2017_sat_math  2017_sat_total  \\\n",
       "0     Alabama              5            593            572            1165   \n",
       "1      Alaska             38            547            533            1080   \n",
       "2     Arizona             30            563            553            1116   \n",
       "3    Arkansas              3            614            594            1208   \n",
       "4  California             53            531            524            1055   \n",
       "\n",
       "   2017_act_part  2017_act_eng  2017_act_math  2017_act_read  \\\n",
       "0            100          18.9           18.4           19.7   \n",
       "1             65          18.7           19.8           20.4   \n",
       "2             62          18.6           19.8           20.1   \n",
       "3            100          18.9           19.0           19.7   \n",
       "4             31          22.5           22.7           23.1   \n",
       "\n",
       "   2017_act_science  ...  2018_sat_part  2018_sat_read  2018_sat_math  \\\n",
       "0              19.4  ...              6            595            571   \n",
       "1              19.9  ...             43            562            544   \n",
       "2              19.8  ...             29            577            572   \n",
       "3              19.5  ...              5            592            576   \n",
       "4              22.2  ...             60            540            536   \n",
       "\n",
       "   2018_sat_total  2018_act_part  2018_act_total  2017_sat_total_standardized  \\\n",
       "0            1166            100            19.1                     0.424770   \n",
       "1            1106             33            20.8                    -0.503344   \n",
       "2            1149             66            19.2                    -0.110260   \n",
       "3            1169            100            19.4                     0.894287   \n",
       "4            1076             27            22.7                    -0.776319   \n",
       "\n",
       "   2018_sat_total_standardized  2017_act_total_standardized  \\\n",
       "0                     0.493207                    -1.159348   \n",
       "1                    -0.150381                    -0.859466   \n",
       "2                     0.310857                    -0.909446   \n",
       "3                     0.525386                    -1.059388   \n",
       "4                    -0.472174                     0.639945   \n",
       "\n",
       "   2018_act_total_standardized  \n",
       "0                    -1.143654  \n",
       "1                    -0.332903  \n",
       "2                    -1.095963  \n",
       "3                    -1.000580  \n",
       "4                     0.573230  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Next, I also wanted to calculate the percent change between 2017 and 2018 scores and participation rates. I created a function for this purpose in the separate Python file._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T21:38:53.821045Z",
     "start_time": "2019-06-12T21:38:53.812725Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final['sat_score_pct_change'] = pct_changer(final['2017_sat_total'], final['2018_sat_total'])\n",
    "final['sat_partication_pct_change'] = pct_changer(final['2017_sat_part'], final['2018_sat_part'])\n",
    "final['act_score_pct_change'] = pct_changer(final['2017_act_total'], final['2018_act_total'])\n",
    "final['act_participation_pct_change'] = pct_changer(final['2017_act_part'], final['2018_act_part'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T21:38:53.852510Z",
     "start_time": "2019-06-12T21:38:53.824554Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>2017_sat_part</th>\n",
       "      <th>2017_sat_read</th>\n",
       "      <th>2017_sat_math</th>\n",
       "      <th>2017_sat_total</th>\n",
       "      <th>2017_act_part</th>\n",
       "      <th>2017_act_eng</th>\n",
       "      <th>2017_act_math</th>\n",
       "      <th>2017_act_read</th>\n",
       "      <th>2017_act_science</th>\n",
       "      <th>...</th>\n",
       "      <th>2018_act_part</th>\n",
       "      <th>2018_act_total</th>\n",
       "      <th>2017_sat_total_standardized</th>\n",
       "      <th>2018_sat_total_standardized</th>\n",
       "      <th>2017_act_total_standardized</th>\n",
       "      <th>2018_act_total_standardized</th>\n",
       "      <th>sat_score_pct_change</th>\n",
       "      <th>sat_partication_pct_change</th>\n",
       "      <th>act_score_pct_change</th>\n",
       "      <th>act_participation_pct_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>5</td>\n",
       "      <td>593</td>\n",
       "      <td>572</td>\n",
       "      <td>1165</td>\n",
       "      <td>100</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.4</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.4</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>19.1</td>\n",
       "      <td>0.424770</td>\n",
       "      <td>0.493207</td>\n",
       "      <td>-1.159348</td>\n",
       "      <td>-1.143654</td>\n",
       "      <td>0.000858</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>-0.005208</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>38</td>\n",
       "      <td>547</td>\n",
       "      <td>533</td>\n",
       "      <td>1080</td>\n",
       "      <td>65</td>\n",
       "      <td>18.7</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.4</td>\n",
       "      <td>19.9</td>\n",
       "      <td>...</td>\n",
       "      <td>33</td>\n",
       "      <td>20.8</td>\n",
       "      <td>-0.503344</td>\n",
       "      <td>-0.150381</td>\n",
       "      <td>-0.859466</td>\n",
       "      <td>-0.332903</td>\n",
       "      <td>0.024074</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>0.050505</td>\n",
       "      <td>-0.492308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>30</td>\n",
       "      <td>563</td>\n",
       "      <td>553</td>\n",
       "      <td>1116</td>\n",
       "      <td>62</td>\n",
       "      <td>18.6</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.1</td>\n",
       "      <td>19.8</td>\n",
       "      <td>...</td>\n",
       "      <td>66</td>\n",
       "      <td>19.2</td>\n",
       "      <td>-0.110260</td>\n",
       "      <td>0.310857</td>\n",
       "      <td>-0.909446</td>\n",
       "      <td>-1.095963</td>\n",
       "      <td>0.029570</td>\n",
       "      <td>-0.033333</td>\n",
       "      <td>-0.025381</td>\n",
       "      <td>0.064516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>3</td>\n",
       "      <td>614</td>\n",
       "      <td>594</td>\n",
       "      <td>1208</td>\n",
       "      <td>100</td>\n",
       "      <td>18.9</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.5</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>19.4</td>\n",
       "      <td>0.894287</td>\n",
       "      <td>0.525386</td>\n",
       "      <td>-1.059388</td>\n",
       "      <td>-1.000580</td>\n",
       "      <td>-0.032285</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>53</td>\n",
       "      <td>531</td>\n",
       "      <td>524</td>\n",
       "      <td>1055</td>\n",
       "      <td>31</td>\n",
       "      <td>22.5</td>\n",
       "      <td>22.7</td>\n",
       "      <td>23.1</td>\n",
       "      <td>22.2</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>22.7</td>\n",
       "      <td>-0.776319</td>\n",
       "      <td>-0.472174</td>\n",
       "      <td>0.639945</td>\n",
       "      <td>0.573230</td>\n",
       "      <td>0.019905</td>\n",
       "      <td>0.132075</td>\n",
       "      <td>-0.004386</td>\n",
       "      <td>-0.129032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        state  2017_sat_part  2017_sat_read  2017_sat_math  2017_sat_total  \\\n",
       "0     Alabama              5            593            572            1165   \n",
       "1      Alaska             38            547            533            1080   \n",
       "2     Arizona             30            563            553            1116   \n",
       "3    Arkansas              3            614            594            1208   \n",
       "4  California             53            531            524            1055   \n",
       "\n",
       "   2017_act_part  2017_act_eng  2017_act_math  2017_act_read  \\\n",
       "0            100          18.9           18.4           19.7   \n",
       "1             65          18.7           19.8           20.4   \n",
       "2             62          18.6           19.8           20.1   \n",
       "3            100          18.9           19.0           19.7   \n",
       "4             31          22.5           22.7           23.1   \n",
       "\n",
       "   2017_act_science  ...  2018_act_part  2018_act_total  \\\n",
       "0              19.4  ...            100            19.1   \n",
       "1              19.9  ...             33            20.8   \n",
       "2              19.8  ...             66            19.2   \n",
       "3              19.5  ...            100            19.4   \n",
       "4              22.2  ...             27            22.7   \n",
       "\n",
       "   2017_sat_total_standardized  2018_sat_total_standardized  \\\n",
       "0                     0.424770                     0.493207   \n",
       "1                    -0.503344                    -0.150381   \n",
       "2                    -0.110260                     0.310857   \n",
       "3                     0.894287                     0.525386   \n",
       "4                    -0.776319                    -0.472174   \n",
       "\n",
       "   2017_act_total_standardized  2018_act_total_standardized  \\\n",
       "0                    -1.159348                    -1.143654   \n",
       "1                    -0.859466                    -0.332903   \n",
       "2                    -0.909446                    -1.095963   \n",
       "3                    -1.059388                    -1.000580   \n",
       "4                     0.639945                     0.573230   \n",
       "\n",
       "   sat_score_pct_change  sat_partication_pct_change  act_score_pct_change  \\\n",
       "0              0.000858                    0.200000             -0.005208   \n",
       "1              0.024074                    0.131579              0.050505   \n",
       "2              0.029570                   -0.033333             -0.025381   \n",
       "3             -0.032285                    0.666667              0.000000   \n",
       "4              0.019905                    0.132075             -0.004386   \n",
       "\n",
       "   act_participation_pct_change  \n",
       "0                      0.000000  \n",
       "1                     -0.492308  \n",
       "2                      0.064516  \n",
       "3                      0.000000  \n",
       "4                     -0.129032  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_I decided to also add four separate datasets to the final dataframe,_ [2016 median income](https://www.census.gov/content/dam/Census/library/publications/2017/acs/acsbr16-02.pdf), [2014 college bound high schoolers](http://www.higheredinfo.org/dbrowser/index.php?submeasure=63&year=2014&level=nation&mode=data&state=0), [2014-2015 Education Revenue by State](https://nces.ed.gov/programs/digest/d17/tables/dt17_235.20.asp?current=yes) and [2017 State Population Estimates](https://www.census.gov/data/tables/2017/demo/popest/state-total.html#par_textimage_1574439295). _The sources are linked. Although the years are not exactly matched up to the 2017 and 2018 tests, this is the most recent information available, and I believe will add valuable insight to the discussion. (Note: District of Columbia information was unavailable for 2014 college bound seniors)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T21:38:53.868642Z",
     "start_time": "2019-06-12T21:38:53.855042Z"
    }
   },
   "outputs": [],
   "source": [
    "# Adding four additional datasets to final,\n",
    "# 2016 median income by state, 2014 college bound high schoolers,\n",
    "# 2014-2015 education revenue by state, and 2017 population estimates by state.\n",
    "median_income = pd.read_csv('./data/median_income_2016.csv')\n",
    "college_bound = pd.read_csv('./data/college_bound.csv')\n",
    "revenue = pd.read_csv('./data/education_revenue.csv')\n",
    "pop = pd.read_csv('./data/2017_pop_est.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T21:38:53.876275Z",
     "start_time": "2019-06-12T21:38:53.870928Z"
    }
   },
   "outputs": [],
   "source": [
    "# The college_bound csv file has a few extraneous columns that I will not be using\n",
    "college_bound.drop(['high_school_grads','full-time_freshmen_2014'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T21:38:53.892011Z",
     "start_time": "2019-06-12T21:38:53.880497Z"
    }
   },
   "outputs": [],
   "source": [
    "final = pd.merge(final, median_income, on='state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T21:38:53.905337Z",
     "start_time": "2019-06-12T21:38:53.893826Z"
    }
   },
   "outputs": [],
   "source": [
    "final = pd.merge(final, college_bound, on='state')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Currently, the revenue dataframe holds state education revenues in thousands. To simplify, I converted the numbers into billions by dividing each value by 1,000,000. The functions that I use can be found in the separate Python file._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T21:38:53.912240Z",
     "start_time": "2019-06-12T21:38:53.907677Z"
    }
   },
   "outputs": [],
   "source": [
    "# The revenue csv file also had 2 NA rows at the bottom of the csv for some reason\n",
    "# So I dropped them\n",
    "revenue = revenue.drop(51)\n",
    "revenue = revenue.drop(52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T21:38:53.920092Z",
     "start_time": "2019-06-12T21:38:53.914182Z"
    }
   },
   "outputs": [],
   "source": [
    "# The revenue data had commas and were string objects, therefore had to clean the data\n",
    "# and divide by one million in order to get the data in billions\n",
    "revenue['education_revenue'] = revenue['education_revenue'].map(remove_commas)\n",
    "revenue['education_revenue'] = revenue['education_revenue'].map(divide_million)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T21:38:53.931703Z",
     "start_time": "2019-06-12T21:38:53.922872Z"
    }
   },
   "outputs": [],
   "source": [
    "final = pd.merge(final,revenue,on='state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T21:38:53.940856Z",
     "start_time": "2019-06-12T21:38:53.937099Z"
    }
   },
   "outputs": [],
   "source": [
    "# The data entries for states had an odd period in the beginning of each name\n",
    "pop['state'] = pop['state'].map(remove_periods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T21:38:53.946840Z",
     "start_time": "2019-06-12T21:38:53.943068Z"
    }
   },
   "outputs": [],
   "source": [
    "# Population had commas and were string objects\n",
    "pop['2017_pop_est'] = pop['2017_pop_est'].map(remove_commas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T21:38:53.960320Z",
     "start_time": "2019-06-12T21:38:53.948880Z"
    }
   },
   "outputs": [],
   "source": [
    "final = pd.merge(final, pop, on='state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T21:39:02.397889Z",
     "start_time": "2019-06-12T21:39:02.392121Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state                            object\n",
       "2017_sat_part                     int64\n",
       "2017_sat_read                     int64\n",
       "2017_sat_math                     int64\n",
       "2017_sat_total                    int64\n",
       "2017_act_part                     int64\n",
       "2017_act_eng                    float64\n",
       "2017_act_math                   float64\n",
       "2017_act_read                   float64\n",
       "2017_act_science                float64\n",
       "2017_act_total                  float64\n",
       "2018_sat_part                     int64\n",
       "2018_sat_read                     int64\n",
       "2018_sat_math                     int64\n",
       "2018_sat_total                    int64\n",
       "2018_act_part                     int64\n",
       "2018_act_total                  float64\n",
       "2017_sat_total_standardized     float64\n",
       "2018_sat_total_standardized     float64\n",
       "2017_act_total_standardized     float64\n",
       "2018_act_total_standardized     float64\n",
       "sat_score_pct_change            float64\n",
       "sat_partication_pct_change      float64\n",
       "act_score_pct_change            float64\n",
       "act_participation_pct_change    float64\n",
       "median_income                     int64\n",
       "college_bound                   float64\n",
       "education_revenue               float64\n",
       "2017_pop_est                      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final check to see if data types were correct\n",
    "final.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T21:39:04.325197Z",
     "start_time": "2019-06-12T21:39:04.302053Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>2017_sat_part</th>\n",
       "      <th>2017_sat_read</th>\n",
       "      <th>2017_sat_math</th>\n",
       "      <th>2017_sat_total</th>\n",
       "      <th>2017_act_part</th>\n",
       "      <th>2017_act_eng</th>\n",
       "      <th>2017_act_math</th>\n",
       "      <th>2017_act_read</th>\n",
       "      <th>2017_act_science</th>\n",
       "      <th>...</th>\n",
       "      <th>2017_act_total_standardized</th>\n",
       "      <th>2018_act_total_standardized</th>\n",
       "      <th>sat_score_pct_change</th>\n",
       "      <th>sat_partication_pct_change</th>\n",
       "      <th>act_score_pct_change</th>\n",
       "      <th>act_participation_pct_change</th>\n",
       "      <th>median_income</th>\n",
       "      <th>college_bound</th>\n",
       "      <th>education_revenue</th>\n",
       "      <th>2017_pop_est</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>5</td>\n",
       "      <td>593</td>\n",
       "      <td>572</td>\n",
       "      <td>1165</td>\n",
       "      <td>100</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.4</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.4</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.159348</td>\n",
       "      <td>-1.143654</td>\n",
       "      <td>0.000858</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>-0.005208</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46257</td>\n",
       "      <td>62.1</td>\n",
       "      <td>7.44</td>\n",
       "      <td>4874747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>38</td>\n",
       "      <td>547</td>\n",
       "      <td>533</td>\n",
       "      <td>1080</td>\n",
       "      <td>65</td>\n",
       "      <td>18.7</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.4</td>\n",
       "      <td>19.9</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.859466</td>\n",
       "      <td>-0.332903</td>\n",
       "      <td>0.024074</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>0.050505</td>\n",
       "      <td>-0.492308</td>\n",
       "      <td>76440</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2.94</td>\n",
       "      <td>739795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>30</td>\n",
       "      <td>563</td>\n",
       "      <td>553</td>\n",
       "      <td>1116</td>\n",
       "      <td>62</td>\n",
       "      <td>18.6</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.1</td>\n",
       "      <td>19.8</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.909446</td>\n",
       "      <td>-1.095963</td>\n",
       "      <td>0.029570</td>\n",
       "      <td>-0.033333</td>\n",
       "      <td>-0.025381</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>53558</td>\n",
       "      <td>52.3</td>\n",
       "      <td>9.86</td>\n",
       "      <td>7016270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>3</td>\n",
       "      <td>614</td>\n",
       "      <td>594</td>\n",
       "      <td>1208</td>\n",
       "      <td>100</td>\n",
       "      <td>18.9</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.5</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.059388</td>\n",
       "      <td>-1.000580</td>\n",
       "      <td>-0.032285</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44334</td>\n",
       "      <td>63.5</td>\n",
       "      <td>5.28</td>\n",
       "      <td>3004279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>53</td>\n",
       "      <td>531</td>\n",
       "      <td>524</td>\n",
       "      <td>1055</td>\n",
       "      <td>31</td>\n",
       "      <td>22.5</td>\n",
       "      <td>22.7</td>\n",
       "      <td>23.1</td>\n",
       "      <td>22.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.639945</td>\n",
       "      <td>0.573230</td>\n",
       "      <td>0.019905</td>\n",
       "      <td>0.132075</td>\n",
       "      <td>-0.004386</td>\n",
       "      <td>-0.129032</td>\n",
       "      <td>67739</td>\n",
       "      <td>60.9</td>\n",
       "      <td>74.40</td>\n",
       "      <td>39536653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        state  2017_sat_part  2017_sat_read  2017_sat_math  2017_sat_total  \\\n",
       "0     Alabama              5            593            572            1165   \n",
       "1      Alaska             38            547            533            1080   \n",
       "2     Arizona             30            563            553            1116   \n",
       "3    Arkansas              3            614            594            1208   \n",
       "4  California             53            531            524            1055   \n",
       "\n",
       "   2017_act_part  2017_act_eng  2017_act_math  2017_act_read  \\\n",
       "0            100          18.9           18.4           19.7   \n",
       "1             65          18.7           19.8           20.4   \n",
       "2             62          18.6           19.8           20.1   \n",
       "3            100          18.9           19.0           19.7   \n",
       "4             31          22.5           22.7           23.1   \n",
       "\n",
       "   2017_act_science  ...  2017_act_total_standardized  \\\n",
       "0              19.4  ...                    -1.159348   \n",
       "1              19.9  ...                    -0.859466   \n",
       "2              19.8  ...                    -0.909446   \n",
       "3              19.5  ...                    -1.059388   \n",
       "4              22.2  ...                     0.639945   \n",
       "\n",
       "   2018_act_total_standardized  sat_score_pct_change  \\\n",
       "0                    -1.143654              0.000858   \n",
       "1                    -0.332903              0.024074   \n",
       "2                    -1.095963              0.029570   \n",
       "3                    -1.000580             -0.032285   \n",
       "4                     0.573230              0.019905   \n",
       "\n",
       "   sat_partication_pct_change  act_score_pct_change  \\\n",
       "0                    0.200000             -0.005208   \n",
       "1                    0.131579              0.050505   \n",
       "2                   -0.033333             -0.025381   \n",
       "3                    0.666667              0.000000   \n",
       "4                    0.132075             -0.004386   \n",
       "\n",
       "   act_participation_pct_change  median_income  college_bound  \\\n",
       "0                      0.000000          46257           62.1   \n",
       "1                     -0.492308          76440           44.0   \n",
       "2                      0.064516          53558           52.3   \n",
       "3                      0.000000          44334           63.5   \n",
       "4                     -0.129032          67739           60.9   \n",
       "\n",
       "   education_revenue  2017_pop_est  \n",
       "0               7.44       4874747  \n",
       "1               2.94        739795  \n",
       "2               9.86       7016270  \n",
       "3               5.28       3004279  \n",
       "4              74.40      39536653  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T21:39:28.151043Z",
     "start_time": "2019-06-12T21:39:28.141324Z"
    }
   },
   "outputs": [],
   "source": [
    "# Outputting into a final .csv file\n",
    "final.to_csv('./data/final.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data dictionary of final dataframe to be used for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|**Feature**|**Type**|**Dataset**|**Description**|\n",
    "|---|---|---|---|\n",
    "|**state**|_object_|---|The state that the average score and subscore for each test was taken|\n",
    "|**2017_act_part** | _integer_ | 2017 ACT Data | The participation rate (as a percent) for each state (and District of Columbia) on the ACT in 2017|\n",
    "|**2017_act_eng** | _float_ | 2017 ACT Data | The average English subscore (out of 36) for each state (and District of Columbia) on the ACT in 2017|\n",
    "|**2017_act_math** | _float_ | 2017 ACT Data | The average Math subscore (out of 36) for each state (and District of Columbia) on the ACT in 2017|\n",
    "|**2017_act_read** | _float_ | 2017 ACT Data | The average Reading subscore (out of 36) for each state (and District of Columbia) on the ACT in 2017|\n",
    "|**2017_act_science** | _float_ | 2017 ACT Data | The average Science subscore (out of 36) for each state (and District of Columbia) on the ACT in 2017|\n",
    "|**2017_act_total** | _float_ | 2017 ACT Data | The average total score (out of 36) on the ACT test for each state in 2017 |\n",
    "|**2017_sat_part** | _int_ | 2017 SAT Data | The participation rate (as a percent) for each state (and District of Columbia) on the SAT in 2017|\n",
    "|**2017_sat_read** | _int_ | 2017 SAT Data | The average Evidence-Based Reading and Writing subscore (out of 800) on the SAT test for each state in 2017|\n",
    "|**2017_sat_math** | _int_ | 2017 SAT Data | The average Math subscore (out of 800) on the SAT test for each state in 2017|\n",
    "|**2017_sat_total** | _int_ | 2017 SAT Data | The average total score (out of 1600) on the SAT test for each state in 2017|\n",
    "|**2018_act_part** | _int_ | 2018 ACT Data | The participation rate (as a percent) for each state (and District of Columbia) on the ACT in 2018|\n",
    "|**2018_act_total** | _float_ | 2018 ACT Data | The average total score (out of 36) on the ACT test for each state in 2018 |\n",
    "|**2018_sat_part** | _int_ | 2018 SAT Data | The participation rate (as a percent) for each state (and District of Columbia) on the SAT in 2018|\n",
    "|**2018_sat_read** | _int_ | 2018 SAT Data | The average Evidence-Based Reading and Writing subscore (out of 800) on the SAT test for each state in 2018|\n",
    "|**2018_sat_math** | _int_ | 2018 SAT Data | The average Math subscore (out of 800) on the SAT test for each state in 2018|\n",
    "|**2018_sat_total** | _int_ | 2018 SAT Data | The average total score (out of 1600) on the SAT test for each state in 2018|\n",
    "|**median_income** | _int_ | 2016 US Census Data | The median income per household for each state in 2016|\n",
    "|**percent_college_bound** | _float_ | 2014 NCES (National Center for Education Statistics) Data  | The percent of college-bound seniors for each state in 2014|\n",
    "|**education_revenue** | _int_ | 2014-2015 NCES (National Center for Education Statistics) Data  | The total education revenue (in millions of dollars) for each state in 2014-2015|\n",
    "|**2017_pop_est** | _int_ | US Census | Estimated population for each state in 2017 by extrapolation from 2010 US Census|\n",
    "|**2017_sat_total_standardized** | _float_ | 2017 SAT Data | The average total score on the SAT test for each state in 2017 standardized by its mean and standard deviation|\n",
    "|**2018_sat_total_standardized** | _float_ | 2018 SAT Data | The average total score on the SAT test for each state in 2018 standardized by its mean and standard deviation|\n",
    "|**2017_act_total_standardized** | _float_ | 2017 ACT Data | The average total score on the ACT test for each state in 2017 standardized by its mean and standard deviation|\n",
    "|**2018_act_total_standardized** | _float_ | 2018 ACT Data | The average total score on the ACT test for each state in 2018 standardized by its mean and standard deviation|\n",
    "|**sat_score_pct_change** | _float_ | 2017 and 2018 SAT Data | The percent change between 2017 and 2018 SAT scores|\n",
    "|**act_score_pct_change** | _float_ | 2017 and 2018 ACT Data | The percent change between 2017 and 2018 ACT scores|\n",
    "|**sat_participation_pct_change** | _float_ | 2017 and 2018 SAT Data | The percent change between 2017 and 2018 SAT participation|\n",
    "|**act_participation_pct_change** | _float_ | 2017 and 2018 ACT Data | The percent change between 2017 and 2018 ACT participation|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_This notebook was used for merging and cleaning data, as well as doing some light feature engineering. The next notebook will look at doing exploratory data analysis and creating visualizations._"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
